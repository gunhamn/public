{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Chunking\n",
    "**1. Create a chunker that detects noun-phrases (NPs) and lists the NPs in the text below.**\n",
    "\n",
    "- Both [NLTK](https://www.nltk.org/book/ch07.html) and [spaCy](https://spacy.io/api/matcher) supports chunking\n",
    "- Look up RegEx parsing for NLTK and the document object for spaCy.\n",
    "- Make use of what you've learned about tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The language model predicted the next word. It was a very nice word!\"\n",
    "# TODO: set up a pos tagger and a chunker.\n",
    "# Output: a list of all tokens, grouped as noun-phrases where applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Modify the chunker to handle verb-phases (VPs) as well.**\n",
    "- This can be done by using a RegEx parser in NLTK or using a spaCy Matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set up grammars to chunk VPs\n",
    "\n",
    "grammar = \"\"\"\n",
    "    VP: {MYGRAMMAR}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Verb-phrases (VPs) can be defined by many different grammatical rules. Give four examples.**\n",
    "- Hint: Context-Free Grammars, chapter 8 in NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. After these applications, do you find chunking to be beneficial in the context of language modeling and next-word prediction? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use spaCy to inspect/visualise the dependency tree of the text provided below.**\n",
    "- Optional addition: visualize the dependencies as a graph using `networkx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The language model predicted the next word\"\n",
    "# TODO: use spacy and displacy to visualize the dependency tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What is the root of the sentence? Attempt to spot it yourself, but the answer should be done by code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement a function to find the root of the document\n",
    "# Return both the word and its POS tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the subject and object of a sentence. Print the results for the sentence above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement a function to find the subjects + objects in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. How would you use the relationships extracted from dependency parsing in language modeling contexts?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use Wordnet (from NLTK) and create a function to get all synonyms of a word of your choice. Try with \"language\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "# TODO: find synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. From the same word you chose, extract an additional 4 or more features from wordnet (such as hyponyms). Describe each category briefly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: expand the function to find more features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Exercise - A sentiment classifier\n",
    "- A rule-based approach with SentiWordNet + A machine learning classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. There are several steps required to build a classifier or any sort of machine learning application for textual data. For data including (INPUT_TEXT, LABEL), list the typical pipeline for classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Before developing a classifier, having a baseline is very useful. Build a baseline model for sentiment classification using SentiWordNet.**\n",
    "- How you decide to aggregate sentiment is up to you. Explain your approach.\n",
    "- It should report the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "\n",
    "\n",
    "# TODO: implement a function to get the sentiment of a text\n",
    "# Must use the sentiwordnet lexicon\n",
    "\n",
    "# Evaluate it on the following sentences:\n",
    "sents = [\n",
    "    \"I liked it! Did you?\",\n",
    "    \"It's not bad but... Nevermind, it is.\",\n",
    "    \"It's awful\",\n",
    "    \"I don't care if you loved it - it was terrible!\",\n",
    "    \"I don't care if you hated it, I think it was awesome\"\n",
    "]\n",
    "# 0: negative, 1: positive\n",
    "y_true = [1, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SST-2 binary sentiment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Split the training set into a training and test set. Choose a split size, and justify your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"sst2\")\n",
    "\n",
    "train_df = dataset[\"train\"].to_pandas().drop(columns=[\"idx\"])\n",
    "train_df = train_df.sample(10000)  # a tiny subset\n",
    "print(train_df.label.value_counts())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split the data\n",
    "train_df = ...\n",
    "test_df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluate your baseline model on the test set.**\n",
    "\n",
    "- Additionally: compare it against a random baseline. That is, a random guess for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate on test set + random guess\n",
    "# Report results in terms of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Did you beat random guess?**\n",
    "\n",
    "If not, can you think of any reasons why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Naive Bayes and TF-IDF\n",
    "This is the final task of the lab. You will use high-level libraries to implement a TF-IDF vectorizer and train your data using a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use scikit-learn to...\n",
    "# - normalize\n",
    "# - vectorize/extract features\n",
    "# - train a classifier\n",
    "# - evaluate the classifier using `classification_report` and `accuracy`\n",
    "# \n",
    "# expect an accuracy of > 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional task: using a pre-trained transformer model\n",
    "If you wish to push the accuracy as far as you can, take a look at BERT-based or other pre-trained language models. As a starting point, take a look at a model already fine-tuned on the SST-2 dataset: [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "\n",
    "**Advanced:**\n",
    "\n",
    "Going beyond this, you could look into the addition of a *classification head* on top of the pooling layer of a BERT-based model. This is a common approach to fine-tuning these models on classification or regression problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
