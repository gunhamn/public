{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "### Published: Monday, Jan. 8, 2024\n",
    "### Deadline: Monday, Jan. 22, 2024\n",
    "\n",
    "Consult the [lab description](lab1_description.md) for background material and suggested reading.\n",
    "\n",
    "Many of these questions will likely feel challenging, as you have not yet been exposed to sufficient background material. They are, however, meant to cover both the curious student and introduce those new to the topics to the world of LLMs.\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "- You must answer at least 10 out of the 21 questions for passing the lab.\n",
    "- Deliver a copy of this notebook on blackboard named `lab1_exercises_{your-username}.ipynb`\n",
    "\n",
    "## Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. A language model (LM) is...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..a type of artificial intelligence that uses natural language as input and output, trained to interpret and generate text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. A large language model (LLM) is...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..a language model that uses vast amounts of parameters and is trained on large datasets, allowing it to \"understand\" and produce text in longer formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. A pre-trained base/foundation model is...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..a large-scale machine learning models, such as a LM, that is yet to be tine-tuned for a specific domain, such as helping a user with instructions or coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What do we mean by fine-tuned language models, and what does the *head* mean in this context?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting out with a foundation model, one can fine-tune it by adding a \"head\", one or more final layers, then further train the model to perform the type of task one wants it to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Which one is more suitable for a chatbot: a pretrained model or a fine-tuned model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned, a foundation model could just as well attempt at predicting your next sentence instead of answering you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. What do we mean by knowledge cutoff in models like ChatGPT?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That the large dataset the foundation model was trained on only stretches to a certain date. The model have no information that was produced after this date. This does not include the fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. What do we mean when we talk about confabulations/hallucinations of LLMs?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that the models claims something to be true that isn't. It often does so with great conviction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. The context length (e.g. 4096) of a GPT-based model is...**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tokens it can consider at once while generating or processing text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Why is it problematic to increase the context/sequence length for transformer-based models?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the computational demand for longer sequences increases quadraticaly due to the nature of the transformers self-attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Parameters are used to describe the model size of LLMs (such as 7B, 13B, â€¦). What do these parameters represent, and what makes LLMs difficult to interpret?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They represent the number of trainable weights in the model. Similiar to all large DNN's, LLM's are difficult to interpret due to the sheer number of parameters in the models. Efforts have been made to recreate parts of neurals networks to understand their nature, but very little progress have been made so far in comparison to how much is left to be understood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Quantization (e.g. through techniques like LoRa, GPTQ, AWQ) is typically used to reduce the size of LLMs allow them to be run on consumer-grade hardware - even laptops! Explain the main idea behind quantization:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization in this context means to reduce the numbers of parameters in a model without loosing too much of its performance. This could be compared to downscaling a song into the small format mp3, making it more easily available, without causong the song quality to drop too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. LLMs need vast training data. The size of training data is typically referred to as tokens. What is a token and what happens to unknown words outside of the models' vocabulary?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A token is the smallest unit of text that a LM processes. This can be a word of part of a word.\n",
    "If the model in its training encounters unknown words, they are typically broken down into smaller known tokens such as words or subwords. Due to the vast training data, LLM's can naturally learn that for example capitalised words can be interpreted as names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. What is the difference between model training and model inference?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model inference is the use of the trained model, where it only produces output and isn't weights are no longer being adjusted based on the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.  Why are GPUs (graphics processing units) ideal for training larger transformer-based models?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are better than CPU's at handling parrallel processing, giving them nore \"bang for the buck\" when purchasing compute for training LLM's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.  What is the biggest technical limitation with respect to GPUs for training LLMs?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LLMs grow bigger and bigger, the number of parameters grow faster than the sizes of the datasets. This makes memory a bottleneck for GPU's, dealing with this vast numbers of parameters that need to be adjusted during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. LLMs aimed towards human interactions should be *aligned*. What does this mean?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THis means that the output should be aligned with human values. This can be promoting human safety and well-being, being politically unbiased or being undiscriminating in the outputs it's producing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17. RLHF (reinforcement learning from human feedback) is used in models like ChatGPT. While you are not expected to learn about reinforcement learning (RL), explain the following terms in context of LLMs (1 sentence each):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SFT (supervised fine-tuning)**\n",
    "    - This is the process of training the foundation model on a premade curated dataset that consists of pairs of inputs and desired outputs.\n",
    "- **Reward model**\n",
    "    - A system trained to evaluate the quality of the model's outputs based on human ratings, guiding the model towards producing \"better\" responses.\n",
    "- **Policy model**\n",
    "    - The final, adapted version of the LLM that has been fine-tuned through RLHF, incorporating the guidance from the reward model to generate improved outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18. For the above procedures, we require data, ideally labeled by humans. This is called data annotation. In this context, what is inter-annotator agreement, and why is it important for model creation?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inter-annotator agreement, or inter-rater reliability, is a measurement of how consistenly the humans give the data the same labels. A low score means that the data labels are unreliable. As always, it's important to train models, such as LM's, on good, reliable data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19. Do you believe LLM projects should be open-sourced? Why?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LLM's get bigger and bigger, their capabilities increase. I think it would be one of the worst ideas in the world to continue to make bigger models open-source. This would open up many possibilities for malign actors such as helping them with hacking, disinformation campaigns, cyber attacks and even biological weapons research.\n",
    "\n",
    "In addition, it could also speed up the progress of general AI capabilities more than it speeds up AI safety research?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20. Why is it important to consider the ethical implications of LLMs?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any system with large capabilities, it's important to consider the ethical implications. Since LLMs have shown potential for advancing developements towards AGI, they should be trained and deployed with the greatest possible consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21. *Smaller* language models ($\\leq 100M$ parameters) will likely be important in the days to come. What are some motivations for smaller models?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less resuorce demanding, less energy consuming, faster, easier to fine-tune, less likely to be regulated. Hopefully more interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "- **What are your expectations for this course? What do you hope to learn?**\n",
    "- **Were the questions too difficult?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feedback to course:**\n",
    "First of, I really this as a first assignment, getting a big-picture overview before diving into the details.\n",
    "\n",
    "**Hopes and dreams:**\n",
    "I hope to understand the foundations of GPT really well and I hope to be capable enough to understand how to build a LLM from scratch (alas not having the compute to train it).\n",
    "\n",
    "**Questions:**\n",
    "I think the questions were a perfect mix of easy and hard. I knew the answers to many from before but most of them forced me to do some research and understand the field better in order to answer neatly in more or less one sentence. I liked that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
