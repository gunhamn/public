{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.12.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import shap\n",
    "from ChestWorld import ChestWorld\n",
    "from dqn_agent_new import DqnAgentNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: 4\n",
      "Observation space: 6\n",
      "Observation space[0]: 6\n",
      "Action space: 4\n",
      "Observation space: 6\n",
      "Observation space[0]: 6\n"
     ]
    }
   ],
   "source": [
    "# Config, load agent and env\n",
    "max_steps=1_000_000\n",
    "\n",
    "# ChestWorld\n",
    "render_mode=None\n",
    "size=6\n",
    "agentSpawn = None\n",
    "q_values=None\n",
    "maxSteps=200\n",
    "stepLoss=-1/maxSteps # min reward should be -1\n",
    "wallCoordinates=None\n",
    "randomWalls=0\n",
    "chestCoordinates=None\n",
    "keyCoordinates=None\n",
    "randomchests=3\n",
    "randomkeys=5\n",
    "chestReward=1/min(randomchests, randomkeys) # max reward should be 1\n",
    "\n",
    "# Agent\n",
    "batch_size=64\n",
    "lr=0.001\n",
    "gamma=0.95\n",
    "epsilon_start=1\n",
    "epsilon_min=0.05\n",
    "epsilon_decay=200_000 # 50_000 at 3000 episodes\n",
    "tau=0.0005 # Was 0.005\n",
    "replayBuffer=100_000\n",
    "\n",
    "env = ChestWorld(render_mode=None, size=size, agentSpawn=agentSpawn, q_values=q_values, stepLoss=stepLoss, maxSteps=maxSteps, wallCoordinates=wallCoordinates, randomWalls=randomWalls, chestCoordinates=chestCoordinates, keyCoordinates=keyCoordinates, chestReward=chestReward, randomchests=randomchests, randomkeys=randomkeys)\n",
    "observation, _ = env.reset()\n",
    "agent = DqnAgentNew(env.action_space, observation,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    gamma=gamma,\n",
    "    epsilon_start=epsilon_start,\n",
    "    epsilon_min=epsilon_min,\n",
    "    epsilon_decay=epsilon_decay,\n",
    "    tau=tau,\n",
    "    replayBuffer=replayBuffer,\n",
    "    wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: C:/Projects/public/XAI_NTNU/modelsToEval/CW_3chests_5keys_6x6_10000000steps.pth\n",
      "1%, time elapsed: 0 minutes and 0.59 seconds, it may finish around: 2024-11-20 15:00:02\n",
      "10%, time elapsed: 0 minutes and 5.89 seconds, it may finish around: 2024-11-20 15:00:03\n",
      "50%, time elapsed: 0 minutes and 27.62 seconds, it may finish around: 2024-11-20 14:59:59\n",
      "99%, time elapsed: 0 minutes and 54.53 seconds, it may finish around: 2024-11-20 14:59:59\n",
      "replayBufferStates shape: torch.Size([100000, 6, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "agent.replayBuffer=replayBuffer\n",
    "agent.load_model_weights(f\"C:/Projects/public/XAI_NTNU/modelsToEval/CW_3chests_5keys_6x6_10000000steps.pth\")\n",
    "agent.inference(env=env, max_steps=100_000, epsilon=epsilon_min)\n",
    "\n",
    "action_direction = {0: \"Right\",1: \"Down\",2: \"Left\", 3: \"Up\"}\n",
    "\n",
    "replayBuffer = agent.replay_buffer\n",
    "replayBufferStates = [replayBuffer[i][0] for i in range(len(replayBuffer))]\n",
    "replayBufferStates = torch.stack(replayBufferStates)\n",
    "replayBufferStates = replayBufferStates.squeeze(1)\n",
    "print(f\"replayBufferStates shape: {replayBufferStates.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background shape: torch.Size([10000, 6, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "model = agent.policy_net\n",
    "# first 100 states\n",
    "background = replayBufferStates[:10_000]\n",
    "#with torch.no_grad():\n",
    "print(f\"Background shape: {background.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = shap.DeepExplainer(model=model,\n",
    "                       data=background,\n",
    "                       session=None,\n",
    "                       learning_phase_flags=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.6630057  0.63042384 0.66851246 0.63307345]\n",
      " [0.7097063  0.65940773 0.7079278  0.66820216]\n",
      " [0.6630057  0.63042384 0.66851246 0.63307345]\n",
      " [0.7097063  0.65940773 0.7079278  0.66820216]\n",
      " [0.6630057  0.63042384 0.66851246 0.63307345]\n",
      " [0.7097063  0.65940773 0.7079278  0.66820216]\n",
      " [0.44284147 0.4169799  0.44803724 0.42762148]\n",
      " [0.1365298  0.10738182 0.08858541 0.12260336]\n",
      " [0.13616663 0.11486167 0.09829283 0.12203023]\n",
      " [0.14867774 0.13298857 0.11465088 0.13913205]]\n",
      "Argmax: ['Left', 'Right', 'Left', 'Right', 'Left', 'Right', 'Left', 'Right', 'Right', 'Right']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of %f is significant compared to the scale of your model outputs, please post as a github issue, with a reproducible example so we can debug it. Used framework: pytorch - Max. diff: 0.6342376136308303 - Tolerance: 0.01",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgmax: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margmax\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_states\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, check_additivity=False)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"AssertionError: The SHAP explanations do not sum up to the\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mmodel's output! This is either because of a rounding error or\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mbecause an operator in your computation graph was not fully\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mwith a reproducible example so we can debug it. Used framework:\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    pytorch - Max. diff: 0.07974889467004687 - Tolerance: 0.01\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# check_additivity was set to False for this reason\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# this error needs to be fixed since it gives a feulty result\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\.venv\\Lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:135\u001b[0m, in \u001b[0;36mDeepExplainer.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Projects\\.venv\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:214\u001b[0m, in \u001b[0;36mPyTorchDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    212\u001b[0m             model_output_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39mX)\n\u001b[1;32m--> 214\u001b[0m     \u001b[43m_check_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_phis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_phis, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# in this case we have multiple inputs and potentially multiple outputs\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_phis[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Projects\\.venv\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_utils.py:20\u001b[0m, in \u001b[0;36m_check_additivity\u001b[1;34m(explainer, model_output_values, output_phis)\u001b[0m\n\u001b[0;32m     16\u001b[0m         diffs \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m output_phis[t][i]\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, output_phis[t][i]\u001b[38;5;241m.\u001b[39mndim)))\n\u001b[0;32m     18\u001b[0m maxdiff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(diffs)\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m maxdiff \u001b[38;5;241m<\u001b[39m TOLERANCE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe SHAP explanations do not sum up to the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms output! This is either because of a \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m     21\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrounding error or because an operator in your computation graph was not fully supported. If \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m     22\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe sum difference of \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m is significant compared to the scale of your model outputs, please post \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m     23\u001b[0m                             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas a github issue, with a reproducible example so we can debug it. Used framework: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplainer\u001b[38;5;241m.\u001b[39mframework\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Max. diff: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaxdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Tolerance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTOLERANCE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of %f is significant compared to the scale of your model outputs, please post as a github issue, with a reproducible example so we can debug it. Used framework: pytorch - Max. diff: 0.6342376136308303 - Tolerance: 0.01"
     ]
    }
   ],
   "source": [
    "test_states = replayBufferStates[10_000:10_010]\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_states).detach().numpy()\n",
    "    argmax = [action_direction[np.argmax(prediction)] for prediction in predictions]\n",
    "    print(f\"Predictions: {predictions}\")\n",
    "    print(f\"Argmax: {argmax}\")\n",
    "\n",
    "shap_values = e.shap_values(test_states) #, check_additivity=False)\n",
    "\"\"\"AssertionError: The SHAP explanations do not sum up to the\n",
    "model's output! This is either because of a rounding error or\n",
    "because an operator in your computation graph was not fully\n",
    "supported. If the sum difference of %f is significant compared\n",
    "to the scale of your model outputs, please post as a github issue,\n",
    "with a reproducible example so we can debug it. Used framework:\n",
    "    pytorch - Max. diff: 0.07974889467004687 - Tolerance: 0.01\"\"\"\n",
    "# check_additivity was set to False for this reason\n",
    "# this error needs to be fixed since it gives a feulty result\n",
    "\n",
    "shap_numpy = list(np.transpose(shap_values, (4, 0, 2, 1, 3)))\n",
    "test_numpy = np.transpose(test_states.numpy(), (0, 2, 1, 3))\n",
    "\n",
    "labels = np.array([[f\"{action_direction[i]}: {predictions[j][i]:.3f}\" for i in range(len(predictions[j]))] for j in range(len(predictions))])\n",
    "\n",
    "# plot the feature attributions\n",
    "shap.image_plot(shap_values=shap_numpy,\n",
    "                pixel_values=test_numpy,\n",
    "                labels=labels,\n",
    "                true_labels=argmax,)\n",
    "#                labelpad=0,\n",
    "#                width=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
