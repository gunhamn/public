{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# import \"C:/Projects/public/XAI_Master/datasets/red1green0.csv\"\n",
    "\n",
    "red1green0 = pd.read_csv(\"C:/Projects/public/XAI_Master/datasets/red1green0.csv\",\n",
    "    header=0,          # Use first row as headers\n",
    "    index_col=None,    # Don't use any column as index\n",
    "    float_precision='high'  # For precise float values\n",
    "    )\n",
    "red0green1 = pd.read_csv(\"C:/Projects/public/XAI_Master/datasets/red0green1.csv\",\n",
    "    header=0,\n",
    "    index_col=None,\n",
    "    float_precision='high'\n",
    "    )\n",
    "\n",
    "# Merge and shuffle the two datasets\n",
    "df = pd.concat([red1green0, red0green1])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\"\"\"\n",
    "df = red0green1\n",
    "\"\"\"\n",
    "x = df.drop(['target', \n",
    "            \"agentX\", \"agentY\",\n",
    "            \"redX\", \"redY\",\n",
    "            \"greenX\", \"greenY\"], axis=1)\n",
    "print(x.shape)\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.1504\n",
      "R2 Score: 0.7538\n",
      "\n",
      "Top 10 most important features by absolute coefficient value:\n",
      "    feature   coefficient\n",
      "68      a69 -4.605642e+09\n",
      "39      a40  3.762482e+09\n",
      "101    a102 -3.596363e+09\n",
      "61      a62  3.091752e+09\n",
      "16      a17  3.075428e+09\n",
      "4        a5 -2.845484e+09\n",
      "29      a30  2.691350e+09\n",
      "125    a126  2.607024e+09\n",
      "18      a19  2.434498e+09\n",
      "44      a45  2.430724e+09\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': x.columns,\n",
    "    'coefficient': model.coef_\n",
    "})\n",
    "\n",
    "print(\"\\nTop 10 most important features by absolute coefficient value:\")\n",
    "print(feature_importance.reindex(feature_importance['coefficient'].abs().sort_values(ascending=False).index)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct predictions: 1568 out of 2000\n",
      "Accuracy: 78.40%\n",
      "\n",
      "Confusion matrix:\n",
      "[[994  32   0]\n",
      " [  5 574   0]\n",
      " [  0 395   0]]\n"
     ]
    }
   ],
   "source": [
    "# Train decision tree\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tree.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "total_correct = (y_test == y_pred).sum()\n",
    "total_samples = len(y_test)\n",
    "\n",
    "print(f\"Total correct predictions: {total_correct} out of {total_samples}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A baseline is established. Between one good red agent and one week green agent, the decision tree managed to predict 78.4% of the cases correctly based on only neuron activations from, fc1, the second last layer with 128 neurons. When also giving the tree the coordinates for the agent, red and greens chests, the tree performed much better, only failing at 7 of 2000 test cases.\n",
    "\n",
    "My thoughts now is that I wonder how much the decision tree learns to identify the neural net and therefore knows if it is a good or bad neural net. I'm also thinking that I need many more neural nets to balance out this, especially very diffferent ones.\n",
    "But probably, the next step is to try with a XAI method instead of activa\n",
    "tions, since it is this comparison which is the most important part of the thesis. Maybe gradcam or shap. SHAP is probably good since it yield a map of what the agent \"focuses\" on. It is also a great baseline for later. So, in short, do shap, and more models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
