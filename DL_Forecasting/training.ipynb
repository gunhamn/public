{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO1_test.csv', 'NO1_train.csv', 'NO1_val.csv', 'NO2_test.csv', 'NO2_train.csv', 'NO2_val.csv', 'NO3_test.csv', 'NO3_train.csv', 'NO3_val.csv', 'NO4_test.csv', 'NO4_train.csv', 'NO4_val.csv', 'NO5_test.csv', 'NO5_train.csv', 'NO5_val.csv']\n",
      "n NO3_train:                    timestamp  consumption  temperature  time_of_day  \\\n",
      "0  2017-05-02 00:00:00+00:00     0.227701     0.450877     0.000000   \n",
      "1  2017-05-02 01:00:00+00:00     0.222187     0.450877     0.043478   \n",
      "2  2017-05-02 02:00:00+00:00     0.226947     0.443860     0.086957   \n",
      "3  2017-05-02 03:00:00+00:00     0.236823     0.431579     0.130435   \n",
      "4  2017-05-02 04:00:00+00:00     0.287226     0.426316     0.173913   \n",
      "\n",
      "   time_of_week  time_of_year  lag_1_hour  lag_24_hours  \n",
      "0      0.166667      0.331507    0.236276      0.246874  \n",
      "1      0.166667      0.331507    0.227701      0.248087  \n",
      "2      0.166667      0.331507    0.222187      0.248142  \n",
      "3      0.166667      0.331507    0.226947      0.250252  \n",
      "4      0.166667      0.331507    0.236823      0.268047  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read the files in the folder preprocessed_datasets\n",
    "path = 'preprocessed_datasets'\n",
    "files = os.listdir(path)\n",
    "files = [file for file in files if file.endswith('.csv')]\n",
    "print(files)\n",
    "\n",
    "NO3_train = pd.read_csv('preprocessed_datasets/NO3_train.csv')\n",
    "NO3_val = pd.read_csv('preprocessed_datasets/NO3_val.csv')\n",
    "NO3_test = pd.read_csv('preprocessed_datasets/NO3_test.csv')\n",
    "\n",
    "print(f\"n NO3_train: {NO3_train.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n NO3_train:    consumption  temperature  time_of_day  time_of_week  time_of_year  \\\n",
      "0     0.227701     0.450877     0.000000      0.166667      0.331507   \n",
      "1     0.222187     0.450877     0.043478      0.166667      0.331507   \n",
      "2     0.226947     0.443860     0.086957      0.166667      0.331507   \n",
      "3     0.236823     0.431579     0.130435      0.166667      0.331507   \n",
      "4     0.287226     0.426316     0.173913      0.166667      0.331507   \n",
      "\n",
      "   lag_1_hour  lag_24_hours  \n",
      "0    0.236276      0.246874  \n",
      "1    0.227701      0.248087  \n",
      "2    0.222187      0.248142  \n",
      "3    0.226947      0.250252  \n",
      "4    0.236823      0.268047  \n",
      "NO3_train.shape: (40920, 7)\n"
     ]
    }
   ],
   "source": [
    "NO3_train = NO3_train.drop('timestamp', axis=1)\n",
    "NO3_val = NO3_val.drop('timestamp', axis=1)\n",
    "NO3_test = NO3_test.drop('timestamp', axis=1)\n",
    "\n",
    "# Separate features and target for the training set\n",
    "NO3_train_features = NO3_train.drop('consumption', axis=1).to_numpy(dtype=np.float32)\n",
    "NO3_train_targets = NO3_train['consumption'].to_numpy(dtype=np.float32)\n",
    "\n",
    "# Separate features and target for the validation set\n",
    "NO3_val_features = NO3_val.drop('consumption', axis=1).to_numpy(dtype=np.float32)\n",
    "NO3_val_targets = NO3_val['consumption'].to_numpy(dtype=np.float32)\n",
    "\n",
    "# Separate features and target for the test set\n",
    "NO3_test_features = NO3_test.drop('consumption', axis=1).to_numpy(dtype=np.float32)\n",
    "NO3_test_targets = NO3_test['consumption'].to_numpy(dtype=np.float32)\n",
    "\n",
    "print(f\"n NO3_train: {NO3_train.head()}\")\n",
    "print(f\"NO3_train.shape: {NO3_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.0-rc0\n",
      "Epoch 1/5\n",
      "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0195 - val_loss: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443us/step - loss: 9.5963e-04 - val_loss: 6.7383e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448us/step - loss: 6.9873e-04 - val_loss: 5.7882e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - loss: 6.0096e-04 - val_loss: 5.1446e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - loss: 5.4421e-04 - val_loss: 4.7727e-04\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 5.9560e-04\n",
      "Validation loss: 0.00047726885532028973\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - loss: 5.6524e-04\n",
      "Test loss: 0.00047388943494297564\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Create a nn with TENSORFLOW to train on the train set, validate on the validation set and test on the test set\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Create the neural network\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(10, activation='relu', input_shape=[6]),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(NO3_train_features, NO3_train_targets, epochs=5, validation_data=(NO3_val_features, NO3_val_targets))\n",
    "\n",
    "# Validate the model\n",
    "val_loss = model.evaluate(NO3_val_features, NO3_val_targets)\n",
    "print(f\"Validation loss: {val_loss}\")\n",
    "\n",
    "# Test the model\n",
    "test_loss = model.evaluate(NO3_test_features, NO3_test_targets)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "# save the model\n",
    "model.save('my_model.keras')\n",
    "print(\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
